"""
general functions for parsing clamlab event ping files generated by bonsai
these are semi-colon(;)-delimited .csv files where each row is
TrialNum, Subject, Value, Timestamp
"""

BONSAI_TIMESTAMP_FMT = "%H:%M:%S.%f"


import pandas as pd, numpy as np
import pyfun.bamboo as boo
import random
from . import runningval


def random_check(anim, running_subj=[]):
    """
    subsess_dict: given some anim, randomly pick a session, and a trial
                  for sanity checking

    running_values: names of subjects to print the most recent value (on current trial, or closest previous trial)
                    note--this doesn't care whether value occurred before or after fixation

    output: prints row summary of randomly-selected trial
            saves raw eventpings of selected trial, and previous, into foo.csv
            prints running values: [val on current trial if found, trial number of found recent val, val]
                --> NB. if running value found for current trial, could have occurred b4/after fixation, so check raw
    """

    print("LOOK IN foo.csv for raw trial pings")
    print()

    subsess_df = random.choice(list(anim.subsess.values()))
    row = subsess_df.sample(n=1).iloc[0]
    subsess_name = row['sess']

    print(anim.name, subsess_name)
    print()

    fn = anim.subsess_paths[subsess_name]['Events']
    df_sess_raw = read_raw(fn)

    trial_num = row['TrialNum']

    df_trial_raw = boo.slice(df_sess_raw, {'TrialNum': [trial_num - 1, trial_num]})
    df_trial_raw.to_csv('foo.csv', index=False)

    vals_all = {}
    for subj_name in running_subj:
        vals_all[subj_name] = runningval.find_recent(df_sess_raw, subj_name, trial_num)

    print(row)
    print()
    print(vals_all)



def read_raw(csv_file, delimiter=';', colnames=["TrialNum", "Subject", "Value", "Timestamp"]):
    """
    reads csv using pandas, with some default formatting
    """

    return pd.read_csv(csv_file, delimiter=delimiter, names=colnames)

def format_prepost_xy(param_prepost, prefix):
    """
    return individual x and y values, pre and post
    """

    param_prepost = [str_to_list(s) for s in param_prepost]  # convert to lists
    output = {}

    for i, pair in enumerate(param_prepost):
        for coord, val in zip(['x', 'y'], pair):
            name = f'{prefix}{i + 1}_{coord}'
            output[name] = val

    return output


def sess_summary(df_sess_raw, sess_name, expt_module):
    """
    process one session raw file and return one info row per trial
    :expt_module: module that contains helper functions and attribs specific to the bonsai experiment
    """

    pre_processor = expt_module.pre_processor
    trial_summarizer = expt_module.trial_summarizer
    running_valuator = expt_module.running_valuator
    colnames = expt_module.COLNAMES


    if len(df_sess_raw) == 0:
        return pd.DataFrame()

    # === pre-process ===
    if pre_processor is not None:
        df_sess_raw = pre_processor(df_sess_raw)
    #df_sess_raw = boo.slice(df_sess_raw, {'TrialNum': [0]}, '-') #remove trial 0

    # === extract values trial by trial and compile into a list ===
    sess_extracts = []

    for TrialNum, df_trial in df_sess_raw.groupby('TrialNum'):
        one_trial = trial_summarizer(df_trial)
        if one_trial is not None:
            sess_extracts.append(one_trial['val'].tolist())

    df_sess = pd.DataFrame(sess_extracts, columns=colnames) #convert list into DataFrame

    if len(df_sess) == 0:
        return pd.DataFrame()

    # === compute running values (can't do separately per trial) ===
    running_vals = running_valuator(df_sess_raw)
    for subj_name, vals in running_vals.items():
        try:
            df_sess = boo.merge_update(df_sess, vals, subj_name, match_column='TrialNum')
        except KeyError: #if dataframe is empty, 'TrialNum' does not exist
            continue

    #one_sess_df['warmup'] = one_sess_df['TrialNum'] <= lora.find_warm_up_done(df_sess)
    df_sess['sess'] = sess_name

    return df_sess


"""
def sess_summary(df_sess_raw, sess_name, colnames, trial_summarizer, pre_processor=None):

    #process one session raw file and return one info row per trial
    #:function trial_summarizer: trial_summary method

    if len(df_sess_raw) == 0:
        return None

    # === pre-process ===
    if pre_processor is not None:
        df_sess_raw = pre_processor(df_sess_raw)
    df_sess_raw = boo.slice(df_sess_raw, {'TrialNum': [0]}, '-') #remove trial 0

    # === extract values trial by trial and compile into a list ===
    sess_extracts = []

    for TrialNum, df_trial in df_sess_raw.groupby('TrialNum'):
        one_trial = trial_summarizer(df_trial)
        if one_trial is not None:
            sess_extracts.append(one_trial['val'].tolist())

    df_sess = pd.DataFrame(sess_extracts, columns=colnames) #convert list into DataFrame

    # === compute running values (can't do separately per trial) ===


    #one_sess_df['warmup'] = one_sess_df['TrialNum'] <= lora.find_warm_up_done(df_sess)
    df_sess['sess'] = sess_name

    if len(df_sess) == 0:
        return None
    else:
        return df_sess
"""

def get_trial_param(df_trial, param, dtype, single=True):
    matches = boo.slice(df_trial, {'Subject': [param]}, '+')['Value'].tolist()

    if len(matches) == 0:
        return None
    elif len(matches)>0:
        #=== type conversion ===
        if dtype=='float':
            matches = [float(s) for s in matches]

        if len(matches) == 1:
            return matches[0]

        #=== check that there are expected number of values ===
        if (len(matches) > 1) and single:
            print(param,'multiple found')
            return matches[-1]

            #TODO fix
            #raise ValueError('Expected single value, but got multiple')

        return matches


def closest_to_row(df, param_name, target_row, neighbors="pre_post"):
    """
    given a target_row, return values (list) of a param (param_name) that occurred closest to it.
    can return just the closest value before target_row,
         or additionally closest value after target_row,

    Useful when different stimuli presented to a trial e.g. when subject restarts fixation,
    and only want to extract the stimulus parameters around successful fixation.

    TODO: set condition for pre only
    """

    matches = boo.slice(df, {'Subject': [param_name]})
    matches.index = matches.index - target_row


    pre = matches.index[matches.index < 0].max()
    post = matches.index[matches.index > 0].min()

    val_all = []
    for loc in [pre, post]:
        if np.isnan(loc):
            val_all.append(None)
        else:
            val_all.append(matches.loc[loc, 'Value'])

    if val_all[1] is None:
        val_all[1] = val_all[0] #param did not change

    return val_all

def str_to_list(input_str, brackets='round', dtype='float'):
    """convert a string representing a list, to a list"""

    if brackets  == 'round':
        to_remove = ['(', ')']
    elif brackets == 'square':
        to_remove = ['[', ']']

    for r in to_remove:
        input_str = input_str.replace(r, '')

    #out_list = [s for s in input_str.split(',')]
    out_list = input_str.split(',')

    if dtype=="float":
        out_list = [float(s) for s in out_list]

    return out_list


def str_to_list_col(df, col, label1, label2, drop=True):
    """
    Takes a DataFrame df with a column (col) of strings representing lists,
    convers these strings to actual lists, then splits into individual columns.
    these columns will be named label1, label2.
    Currently only handles length-2 lists.

    TODO: expand to more general case where it's a list of arbitary length
    """

    df = df.copy()
    xy_series = df['Value'].apply(lambda lst_str: str_to_list(lst_str))
    xy_arr = np.array(xy_series.tolist())

    if xy_arr.shape[1] != 2:
        raise ValueError('Lists should be length 2.')

    df[label1] = xy_arr[:, 0]
    df[label2] = xy_arr[:, 1]

    if drop:
        df = df.drop(col, axis=1)

    return df