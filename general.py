"""
general functions for parsing clamlab event ping files generated by bonsai
these are semi-colon(;)-delimited .csv files where each row is
TrialNum, Subject, Value, Timestamp
"""

BONSAI_TIMESTAMP_FMT = "%H:%M:%S.%f"


import pandas as pd, numpy as np
import pyfun.bamboo as boo


def create_index_dict(df, column_name, return_type='first', error_on_multiple=True):
    """
    Creates a dictionary with unique column values as keys and their respective indices as values.

    Parameters:
    - df (pd.DataFrame): The input DataFrame.
    - column_name (str): The name of the column to create the dictionary from.
    - return_type (str, optional): Type of indices to return; can be 'all', 'first', or 'last'. Default is 'all'.
    - error_on_multiple (bool, optional): If True, raises a ValueError when multiple indices are found and return_type is not 'all'. Default is False.

    Returns:
    - dict: A dictionary with unique column values as keys and indices as values.
    """

    # Check if the column_name exists in the DataFrame
    if column_name not in df.columns:
        raise ValueError(f"Column '{column_name}' not found in DataFrame")

    # Check if return_type is valid
    if return_type not in ['all', 'first', 'last']:
        raise ValueError("return_type must be one of ['all', 'first', 'last']")

    # Creating the dictionary
    trial_dict = {key: list(value.index) for key, value in df.groupby(column_name)}

    # Modify the dictionary based on return_type and error_on_multiple
    if return_type in ['first', 'last']:
        for key, indices in trial_dict.items():
            if error_on_multiple and len(indices) > 1:
                raise ValueError(f"Multiple indices found for '{key}' in column '{column_name}'")
            trial_dict[key] = indices[0] if return_type == 'first' else indices[-1]

    return trial_dict


def get_trial_event_indices(df_raw, event_name):
    trialnum_col = 'TrialNum'
    df = boo.slice(df_raw, {'Value': [event_name]})[[trialnum_col]]
    indices_dict = create_index_dict(df, trialnum_col)

    return indices_dict


def get_values_closest_to_event(filledin, event_indices, trialnum_col='TrialNum', value_col='Value'):
    data = []

    for trialnum, event_idx in event_indices.items():
        # Filter rows for current TrialNum that are before the event index
        filtered_rows = filledin[(filledin[trialnum_col] == trialnum) & (filledin.index < event_idx)]

        if not filtered_rows.empty:
            # Take the last row as it's the closest before the event
            closest_row = filtered_rows.iloc[-1]
            data.append({
                trialnum_col: trialnum,
                value_col: closest_row[value_col]
            })

    return pd.DataFrame(data)


def runningval_insert(df, trialnum_col='TrialNum', value_col='Value'):
    """
    This function inserts rows in the dataframe for every trial number and for any missing trial numbers.
    Each new row takes the value of the preceding trial.
    """
    # Sort DataFrame based on trialnum_col for consistency
    df = df.sort_values(by=trialnum_col)

    insertion_index_offset = 0.00001
    prev_trial_value = None
    prev_trial_num = None
    prev_index = None

    rows_to_insert = []

    for index, row in df.iterrows():
        current_trialnum = row[trialnum_col]
        current_value = row[value_col]

        # If we've processed at least one row before
        if prev_trial_num is not None:
            # Check for missing trial numbers and fill them in
            for missing_trial_num in range(prev_trial_num + 1, current_trialnum):
                prev_index += insertion_index_offset
                rows_to_insert.append((prev_index, missing_trial_num, prev_trial_value))

            # Append the row for the current trial
            prev_index += insertion_index_offset
            rows_to_insert.append((prev_index, current_trialnum, prev_trial_value))

        prev_trial_value = current_value
        prev_trial_num = current_trialnum
        prev_index = index

    # Add the new rows to the dataframe
    for idx, trialnum, value in rows_to_insert:
        df.loc[idx] = {trialnum_col: trialnum, value_col: value}

    # Sort by index to ensure the new rows are in the correct place
    df = df.sort_index()

    return df


def read_raw(csv_file, delimiter=';', colnames=["TrialNum", "Subject", "Value", "Timestamp"]):
    """
    reads csv using pandas, with some default formatting
    """

    return pd.read_csv(csv_file, delimiter=delimiter, names=colnames)

def format_prepost_xy(param_prepost, prefix):
    """
    return individual x and y values, pre and post
    """

    param_prepost = [str_to_list(s) for s in param_prepost]  # convert to lists
    output = {}

    for i, pair in enumerate(param_prepost):
        for coord, val in zip(['x', 'y'], pair):
            name = f'{prefix}{i + 1}_{coord}'
            output[name] = val

    return output



def sess_summary(df_sess, sess_name, colnames, trial_summarizer):
    """
    process one session raw file and return one info row per trial
    :function trial_summarizer: trial_summary method
    """

    one_sess = []
    df_sess = boo.slice(df_sess, {'TrialNum': [0]}, '-') #remove trial 0
    for TrialNum, df_trial in df_sess.groupby('TrialNum'):
        one_trial = trial_summarizer(df_trial)
        if one_trial is not None:
            one_sess.append(one_trial['val'].tolist())

    one_sess_df = pd.DataFrame(one_sess, columns=colnames)

    #one_sess_df['warmup'] = one_sess_df['TrialNum'] <= lora.find_warm_up_done(df_sess)
    one_sess_df['sess'] = sess_name

    return one_sess_df


def get_trial_param(df_trial, param, dtype, single=True):
    matches = boo.slice(df_trial, {'Subject': [param]}, '+')['Value'].tolist()

    if len(matches) == 0:
        return None
    elif len(matches)>0:
        #=== type conversion ===
        if dtype=='float':
            matches = [float(s) for s in matches]

        if len(matches) == 1:
            return matches[0]

        #=== check that there are expected number of values ===
        if (len(matches) > 1) and single:
            print('multiple found')
            return matches[-1]

            #TODO fix
            #raise ValueError('Expected single value, but got multiple')

        return matches


def closest_to_row(df, param_name, target_row, neighbors="pre_post"):
    """
    given a target_row, return values of a param (param_name) that occurred closest to it.
    can return just the closest value before target_row,
         or additionally closest value after target_row,

    Useful when different stimuli presented to a trial e.g. when subject restarts fixation,
    and only want to extract the stimulus parameters around successful fixation.

    TODO: set condition for pre only
    """

    matches = boo.slice(df, {'Subject': [param_name]})
    matches.index = matches.index - target_row


    pre = matches.index[matches.index < 0].max()
    post = matches.index[matches.index > 0].min()

    val_all = []
    for loc in [pre, post]:
        if np.isnan(loc):
            val_all.append(None)
        else:
            val_all.append(matches.loc[loc, 'Value'])

    if val_all[1] is None:
        val_all[1] = val_all[0] #param did not change

    return val_all

def str_to_list(input_str, brackets='round', dtype='float'):
    """convert a string representing a list, to a list"""

    if brackets  == 'round':
        to_remove = ['(', ')']
    elif brackets == 'square':
        to_remove = ['[', ']']

    for r in to_remove:
        input_str = input_str.replace(r, '')

    #out_list = [s for s in input_str.split(',')]
    out_list = input_str.split(',')

    if dtype=="float":
        out_list = [float(s) for s in out_list]

    return out_list


def str_to_list_col(df, col, label1, label2, drop=True):
    """
    Takes a DataFrame df with a column (col) of strings representing lists,
    convers these strings to actual lists, then splits into individual columns.
    these columns will be named label1, label2.
    Currently only handles length-2 lists.

    TODO: expand to more general case where it's a list of arbitary length
    """

    df = df.copy()
    xy_series = df['Value'].apply(lambda lst_str: str_to_list(lst_str))
    xy_arr = np.array(xy_series.tolist())

    if xy_arr.shape[1] != 2:
        raise ValueError('Lists should be length 2.')

    df[label1] = xy_arr[:, 0]
    df[label2] = xy_arr[:, 1]

    if drop:
        df = df.drop(col, axis=1)

    return df