"""
general functions for parsing clamlab event ping files generated by bonsai
these are semi-colon(;)-delimited .csv files where each row is
TrialNum, Subject, Value, Timestamp
"""

BONSAI_TIMESTAMP_FMT = "%H:%M:%S.%f"


import pandas as pd, numpy as np
import pyfun.bamboo as boo
import os
import glob
import importlib


def amend_processed(amendments_directory, expt):
    """
    applies corrections to processed dataframes
    assumes that processed dfs are expt.anim.big_df
    """

    search_str = os.path.join(amendments_directory, '*.py')
    amendment_scripts = sorted(glob.glob(search_str))

    n = 0
    for script_path in amendment_scripts:
        module_name = os.path.splitext(os.path.basename(script_path))[0]
        spec = importlib.util.spec_from_file_location(module_name, script_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        if hasattr(module, 'amend'):
            expt = module.amend(expt)
            n+=1
        else:
            print(f"No amend function in {module_name}")

    print(n, 'corrections made.')
    return expt



def read_raw(csv_file, delimiter=';', colnames=["TrialNum", "Subject", "Value", "Timestamp"]):
    """
    reads csv using pandas, with some default formatting
    """

    return pd.read_csv(csv_file, delimiter=delimiter, names=colnames)

def format_prepost_xy(param_prepost, prefix):
    """
    return individual x and y values, pre and post
    """

    param_prepost = [str_to_list(s) for s in param_prepost]  # convert to lists
    output = {}

    for i, pair in enumerate(param_prepost):
        for coord, val in zip(['x', 'y'], pair):
            name = f'{prefix}{i + 1}_{coord}'
            output[name] = val

    return output


def events_summary(df_sess_raw, sess_name, expt_module):
    """
    process one session raw file and return one row per trial,
    columns containing per-trial variables e.g. stimulus, animal choices...
    :expt_module: module that contains helper functions
    and attribs specific to the bonsai experiment
    """

    pre_processor = expt_module._pre_processor
    trial_summarizer = expt_module._trial_summarizer
    running_valuator = expt_module._running_valuator
    post_processor = expt_module._post_processor
    colnames = expt_module.COLNAMES


    if len(df_sess_raw) == 0:
        return pd.DataFrame()

    # === pre-process ===
    if pre_processor is not None:
        df_sess_raw = pre_processor(df_sess_raw)
    #df_sess_raw = boo.slice(df_sess_raw, {'TrialNum': [0]}, '-') #remove trial 0. May need to preserve for older csvs which still require running valuators

    # === extract values trial by trial and compile into a list ===
    sess_extracts = []

    for TrialNum, df_trial in df_sess_raw.groupby('TrialNum'):
        one_trial = trial_summarizer(df_trial)
        if one_trial is not None:
            sess_extracts.append(one_trial['val'].tolist())

    df_sess = pd.DataFrame(sess_extracts, columns=colnames) #convert list into DataFrame

    if len(df_sess) == 0:
        return pd.DataFrame()

    # === compute running values (can't do separately per trial) ===
    running_vals = running_valuator(df_sess_raw)
    for subj_name, vals in running_vals.items():
        try:
            df_sess = boo.merge_update(df_sess, vals, subj_name, match_column='TrialNum')
        except KeyError: #if dataframe is empty, 'TrialNum' does not exist
            continue

    df_sess['sess'] = sess_name

    if post_processor is not None:
        df_sess = post_processor(df_sess)

    return df_sess

def get_trial_param(df_trial, param, dtype, single):
    matches = boo.slice(df_trial, {'Subject': [param]}, '+')['Value'].tolist()

    if len(matches) == 0:
        return None
    elif len(matches) > 0:
        #=== type conversion ===
        #if no conversion, it remains as string
        if dtype == 'float':
            matches = [float(s) for s in matches]
        elif dtype == 'int':
            matches = [int(s) for s in matches]


        if len(matches) == 1:
            return matches[0]
        else: #len(matches) > 1
            if single == 'last':
                return matches[-1] #return the last value
            elif single == 'strict':
                raise ValueError('Expected single value, but got multiple')
            else:
                err_msg = "Multiple matches found, but unknown single parameter" + single
                raise ValueError(err_msg)


def closest_to_row(df, param_name, target_row, neighbors="pre_post"):
    """
    given a target_row, return values (list) of a param (param_name) that occurred closest to it.
    can return just the closest value before target_row,
         or additionally closest value after target_row,

    Useful when different stimuli presented to a trial e.g. when subject restarts fixation,
    and only want to extract the stimulus parameters around successful fixation.

    TODO: set condition for pre only
    """

    matches = boo.slice(df, {'Subject': [param_name]})
    matches.index = matches.index - target_row


    pre = matches.index[matches.index < 0].max()
    post = matches.index[matches.index > 0].min()

    val_all = []
    for loc in [pre, post]:
        if np.isnan(loc):
            val_all.append(None)
        else:
            val_all.append(matches.loc[loc, 'Value'])

    if val_all[1] is None:
        val_all[1] = val_all[0] #param did not change

    return val_all

def str_to_list(input_str, brackets='round', dtype='float'):
    """convert a string representing a list, to a list"""

    if brackets  == 'round':
        to_remove = ['(', ')']
    elif brackets == 'square':
        to_remove = ['[', ']']

    for r in to_remove:
        input_str = input_str.replace(r, '')

    try:

        out_list = input_str.split(',')

        if dtype=="float":
            out_list = [float(s) for s in out_list]

        if len(out_list) != 2:
            return (None, None)

    except ValueError:
        return (None, None)

    return out_list


def str_to_list_col(df, col, label1, label2, drop=True):
    """
    Takes a DataFrame df with a column (col) of strings representing lists,
    convers these strings to actual lists, then splits into individual columns.
    these columns will be named label1, label2.
    Currently only handles length-2 lists.

    TODO: expand to more general case where it's a list of arbitary length
    """

    df = df.copy()
    xy_series = df['Value'].apply(lambda lst_str: str_to_list(lst_str))
    xy_arr = np.array(xy_series.tolist())

    if xy_arr.shape[1] != 2:
        raise ValueError('Lists should be length 2.')

    df[label1] = xy_arr[:, 0]
    df[label2] = xy_arr[:, 1]

    if drop:
        df = df.drop(col, axis=1)

    return df